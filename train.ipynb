{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sabbi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "# set the configuration\n",
    "import configparser\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "\n",
    "from models import UNet\n",
    "from models.deeplab import get_deeplab\n",
    "\n",
    "\n",
    "import seg_data\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomImageDataset(Dataset):\n",
    "#     def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "#         self.img_labels = pd.read_csv(annotations_file)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "#         image = read_image(img_path)\n",
    "#         label = self.img_labels.iloc[idx, 1]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         if self.target_transform:\n",
    "#             label = self.target_transform(label)\n",
    "#         return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dice coefficient\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    assert input.size() == target.size()\n",
    "    assert input.dim() == 3 or not reduce_batch_first\n",
    "\n",
    "    sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n",
    "\n",
    "    inter = 2 * (input * target).sum(dim=sum_dim)\n",
    "    sets_sum = input.sum(dim=sum_dim) + target.sum(dim=sum_dim)\n",
    "    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
    "\n",
    "    dice = (inter + epsilon) / (sets_sum + epsilon)\n",
    "    return dice.mean()\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "    # Average of Dice coefficient for all classes\n",
    "    return dice_coeff(input.flatten(0, 1), target.flatten(0, 1), reduce_batch_first, epsilon)\n",
    "\n",
    "\n",
    "def dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(input, target, reduce_batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,model_name, dataloader, device, amp = True):\n",
    "    \"\"\"Evaluate the validation set\n",
    "\n",
    "    Return validation score (dice score).\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_val_batches = len(dataloader)\n",
    "    dice_score = 0\n",
    "    valid_loss = 0\n",
    "    # iterate over the validation set\n",
    "    with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "        for batch in dataloader:\n",
    "            images, mask_true = batch[0], batch[1]\n",
    "\n",
    "            # move images and labels to correct device and type\n",
    "            images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            mask_true = mask_true.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            # predict the mask\n",
    "            mask_pred = model(images)\n",
    "\n",
    "            if model_name==\"deeplab\":\n",
    "                mask_pred = mask_pred['out']\n",
    "\n",
    "        if model.n_classes == 1:\n",
    "            \n",
    "            loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
    "        else:\n",
    "            loss = criterion(masks_pred, true_masks)\n",
    "\n",
    "            if model.n_classes == 1:\n",
    "                assert mask_true.min() >= 0 and mask_true.max() <= 1, 'True mask indices should be in [0, 1]'\n",
    "                valid_loss += criterion(masks_pred.squeeze(1), mask_true.float())\n",
    "\n",
    "                mask_pred = (F.sigmoid(mask_pred) > 0.5).float()\n",
    "                # compute the Dice score\n",
    "                dice_score += dice_coeff(mask_pred, mask_true, reduce_batch_first=False)\n",
    "            else:\n",
    "                assert mask_true.min() >= 0 and mask_true.max() < model.n_classes, 'True mask indices should be in [0, n_classes['\n",
    "                # convert to one-hot format\n",
    "                valid_loss += criterion(masks_pred, true_masks)\n",
    "                mask_true = F.one_hot(mask_true.argmax(dim=1).to(torch.long), model.n_classes).permute(0, 3, 1, 2).float()\n",
    "                mask_pred = F.one_hot(mask_pred.argmax(dim=1), model.n_classes).permute(0, 3, 1, 2).float()\n",
    "                # compute the Dice score, ignoring background\n",
    "                dice_score += multiclass_dice_coeff(mask_pred[:, 1:], mask_true[:, 1:], reduce_batch_first=False)\n",
    "\n",
    "    model.train()\n",
    "    return dice_score / max(num_val_batches, 1) , valid_loss/ max(num_val_batches, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIR\n",
      "('image_dir', 'C:\\\\Users\\\\sabbi\\\\Downloads\\\\project1\\\\data_demo\\\\img_crop_pad')\n",
      "('mask_dir', 'C:\\\\Users\\\\sabbi\\\\Downloads\\\\project1\\\\data_demo\\\\mask_crop_pad')\n",
      "('checkpoint_path', 'C:\\\\Users\\\\sabbi\\\\Downloads\\\\project1\\\\models\\\\checkpoint\\\\unet_checkpoint_epoch30.pth')\n",
      "('log_dir', './logs/')\n",
      "PARAMS\n",
      "('model', 'unet')\n",
      "('start_class_i', '0')\n",
      "('scale', '1')\n",
      "('n_classes', '3')\n",
      "('img_aug', 'TRUE')\n",
      "('epochs', '15')\n",
      "('learning_rate', '0.01')\n",
      "('batch_size', '2')\n",
      "('val_percent', '15')\n",
      "UNET\n",
      "('bilinear', 'TRUE')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "## Read the config\n",
    "def read_ini(file_path):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(file_path)\n",
    "    return config\n",
    "\n",
    " \n",
    "config = read_ini(\"./train_config.ini\")\n",
    "\n",
    "for section in config.sections():\n",
    "    print(section)\n",
    "    for key in config[section]:\n",
    "        print((key, config[section][key]))\n",
    "\n",
    "\n",
    "img_path = config[\"DIR\"][\"image_dir\"]\n",
    "mask_path =config[\"DIR\"][\"mask_dir\"]\n",
    "checkpoint_path = config[\"DIR\"][\"checkpoint_path\"]\n",
    "\n",
    "start_class_i = int(config[\"PARAMS\"].get('start_class_i',0))\n",
    "model_name = config[\"PARAMS\"]['model']\n",
    "scale = int(config[\"PARAMS\"][\"scale\"])\n",
    "\n",
    "learning_rate = float(config[\"PARAMS\"]['learning_rate'])\n",
    "batch_size = int(config[\"PARAMS\"]['batch_size'])\n",
    "val_percent = int(config[\"PARAMS\"]['val_percent'])\n",
    "\n",
    "# number of classes\n",
    "n_classes = int(config[\"PARAMS\"].get('n_classes',False))\n",
    "# Class weight, if not specified, assign None\n",
    "class_weights = config[\"PARAMS\"].get('class_weights',False)\n",
    "if class_weights:\n",
    "    \n",
    "    class_weights = eval(class_weights)\n",
    "    assert len(class_weights) == n_classes, \"The length of class weights: {} should equal to the number of classes: {}\".format(len(class_weights),n_classes)\n",
    "    class_weights_tensor = torch.tensor(class_weights)\n",
    "    class_weights = True\n",
    "\n",
    "epochs = int(config[\"PARAMS\"]['epochs'])\n",
    "\n",
    "\n",
    "\n",
    "# n_classes = config\n",
    "\n",
    "# config.get(\"UNET\")\n",
    "if model_name == \"unet\" and \"UNET\" in config:\n",
    "    bilinear = config[\"UNET\"][\"bilinear\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "        Image folder: C:\\Users\\sabbi\\Downloads\\project1\\data_demo\\img_crop_pad\n",
      "        input image scale: 1\n",
      "        Mask folder: C:\\Users\\sabbi\\Downloads\\project1\\data_demo\\mask_crop_pad\n",
      "        Dataset length: 147\n",
      "        Validation set percentage: 15\n",
      "        Batch size: 2\n",
      "    \n",
      "System info:\n",
      "        Using device: cpu\n",
      "        CPU cores: 16\n",
      "        GPU count: 0\n",
      "\n",
      "No class weight in loss\n",
      "Model info:\n",
      "        Model name: unet\n",
      "        \n",
      "        Output channels: 3\n",
      "        Epochs: 15\n",
      "        Learning Rate: 0.01\n",
      "        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read and init datasets\n",
    "dataset_whole = seg_data.segDataset(img_path = img_path, \n",
    "    mask_path = mask_path, n_classes=n_classes,\n",
    "    scale=scale , start_class_i = start_class_i)\n",
    "\n",
    "# dataset = seg_data.segDataset(img_path = img_path, \n",
    "#     mask_path = mask_path,\n",
    "#     scale=scale)\n",
    "\n",
    "# Split and create dataloader\n",
    "l=dataset_whole.__len__()\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset_whole)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset_whole, indices[:-int(np.ceil(l*val_percent/100))])\n",
    "dataset_val = torch.utils.data.Subset(dataset_whole, indices[int(-np.ceil(l*val_percent/100)):])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset_val, batch_size=1,\n",
    "                                        shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f'''Dataset info:\n",
    "        Image folder: {img_path}\n",
    "        input image scale: {scale}\n",
    "        Mask folder: {mask_path}\n",
    "        Dataset length: {l}\n",
    "        Validation set percentage: {val_percent}\n",
    "        Batch size: {batch_size}\n",
    "    ''')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'''System info:\n",
    "        Using device: {device}\n",
    "        CPU cores: {os.cpu_count()}\n",
    "        GPU count: {torch.cuda.device_count()}\n",
    "'''\n",
    ")\n",
    "\n",
    "\n",
    "# init model and device\n",
    "\n",
    "\n",
    "\n",
    "### Unet ###\n",
    "if model_name =='unet':\n",
    "    model = UNet(n_channels=3, n_classes=n_classes, bilinear=bilinear)\n",
    "elif model_name ==\"deeplab\":\n",
    "    model = get_deeplab(n_classes)\n",
    "    \n",
    "# switch NCHW to NHWC\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "model.to(device=device)\n",
    "\n",
    "# Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "optimizer = optim.RMSprop(model.parameters(),\n",
    "                            lr=learning_rate, foreach=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "# grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "\n",
    "# Loss function\n",
    "if class_weights:\n",
    "    print(\"Using class weight in loss: {}\".format(class_weights_tensor))\n",
    "    class_weights_tensor = class_weights_tensor.to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight= class_weights_tensor) if n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "# Loss function with class weight\n",
    "else:\n",
    "    print(\"No class weight in loss\")\n",
    "    criterion = nn.CrossEntropyLoss() if n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "scaler=None\n",
    "\n",
    "# Learning rate warm up\n",
    "warmup_factor = 1.0 / 1000\n",
    "warmup_iters = min(1000, len(train_loader) - 1)\n",
    "warm_up_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'''Model info:\n",
    "        Model name: {model_name}\n",
    "        \n",
    "        Output channels: {n_classes}\n",
    "        Epochs: {epochs}\n",
    "        Learning Rate: {learning_rate}\n",
    "        \n",
    "''')\n",
    " \n",
    "#{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling\n",
    "\n",
    "\n",
    "\n",
    "# if args.load:\n",
    "#     state_dict = torch.load(args.load, map_location=device)\n",
    "#     del state_dict['mask_values']\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No class weight in loss\n",
      "Model info:\n",
      "        Model name: unet\n",
      "        \n",
      "        Output channels: 3\n",
      "        Epochs: 15\n",
      "        Learning Rate: 0.01\n",
      "        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init model and device\n",
    "\n",
    "\n",
    "\n",
    "### Unet ###\n",
    "if model_name =='unet':\n",
    "    model = UNet(n_channels=3, n_classes=n_classes, bilinear=bilinear)\n",
    "elif model_name ==\"deeplab\":\n",
    "    model = get_deeplab(n_classes)\n",
    "    \n",
    "# switch NCHW to NHWC\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "model.to(device=device)\n",
    "\n",
    "# Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "optimizer = optim.RMSprop(model.parameters(),\n",
    "                            lr=learning_rate, foreach=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "# grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "\n",
    "# Loss function\n",
    "if class_weights:\n",
    "    print(\"Using class weight in loss: {}\".format(class_weights_tensor))\n",
    "    class_weights_tensor = class_weights_tensor.to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight= class_weights_tensor) if n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "# Loss function with class weight\n",
    "else:\n",
    "    print(\"No class weight in loss\")\n",
    "    criterion = nn.CrossEntropyLoss() if n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "scaler=None\n",
    "\n",
    "# Learning rate warm up\n",
    "warmup_factor = 1.0 / 1000\n",
    "warmup_iters = min(1000, len(train_loader) - 1)\n",
    "warm_up_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'''Model info:\n",
    "        Model name: {model_name}\n",
    "        \n",
    "        Output channels: {n_classes}\n",
    "        Epochs: {epochs}\n",
    "        Learning Rate: {learning_rate}\n",
    "        \n",
    "''')\n",
    " \n",
    "#{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling\n",
    "\n",
    "\n",
    "\n",
    "# if args.load:\n",
    "#     state_dict = torch.load(args.load, map_location=device)\n",
    "#     del state_dict['mask_values']\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1/15\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n",
      "torch.Size([2, 3, 1405, 1368]) torch.Size([2, 3, 1405, 1368])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 56\u001b[0m\n\u001b[0;32m     51\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Validation stage\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Validation stage\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m val_score,val_loss \u001b[38;5;241m=\u001b[39m evaluate(model,model_name, test_loader, device)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# writer.add_scalar('Loss/Valid', epoch_loss, epoch)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss/Valid\u001b[39m\u001b[38;5;124m'\u001b[39m , val_loss, epoch)\n",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, model_name, dataloader, device, amp)\u001b[0m\n\u001b[0;32m     18\u001b[0m mask_true \u001b[38;5;241m=\u001b[39m mask_true\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# predict the mask\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m mask_pred \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeeplab\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     24\u001b[0m     mask_pred \u001b[38;5;241m=\u001b[39m mask_pred[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\project1\\models\\unet_model.py:31\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m x4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown3(x3)\n\u001b[0;32m     30\u001b[0m x5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown4(x4)\n\u001b[1;32m---> 31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup1(x5, x4)\n\u001b[0;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup2(x, x3)\n\u001b[0;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup3(x, x2)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\project1\\models\\unet_parts.py:68\u001b[0m, in \u001b[0;36mUp.forward\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# if you have padding issues, see\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\u001b[39;00m\n\u001b[0;32m     67\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x2, x1], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\project1\\models\\unet_parts.py:25\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdouble_conv(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "# 5. Begin training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    print(\"Training epoch: {}/{}\".format(epoch,epochs))\n",
    "    for batch in train_loader:\n",
    "        images, true_masks = batch[0], batch[1]\n",
    "\n",
    "        # assert images.shape[1] == model.n_channels, \\\n",
    "        #     f'Network has been defined with {model.n_channels} input channels, ' \\\n",
    "        #     f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "        #     'the images are loaded correctly.'\n",
    "        \n",
    "\n",
    "        images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "        true_masks = true_masks.to(device=device, dtype=torch.float32)\n",
    "        \n",
    "\n",
    "        masks_pred = model(images)\n",
    "\n",
    "        if model_name ==\"deeplab\":\n",
    "            masks_pred = masks_pred['out']\n",
    "\n",
    "        print(true_masks.shape, masks_pred.shape)\n",
    "        if model.n_classes == 1:\n",
    "            loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
    "            loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
    "        else:\n",
    "            loss = criterion(masks_pred, true_masks)\n",
    "            loss += dice_loss(\n",
    "                F.softmax(masks_pred, dim=1).float(),\n",
    "                F.one_hot(true_masks.argmax(dim=1), model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                multiclass=True\n",
    "            )\n",
    "        writer.add_scalar('Loss/train', loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch == 0:\n",
    "            warm_up_scheduler.step()\n",
    "        \n",
    "        # Update the global step and epoch loss\n",
    "        global_step += 1\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    \n",
    "    # Validation stage\n",
    "    # Validation stage\n",
    "    val_score,val_loss = evaluate(model,model_name, test_loader, device)\n",
    "    # writer.add_scalar('Loss/Valid', epoch_loss, epoch)\n",
    "    writer.add_scalar('Loss/Valid' , val_loss, epoch)\n",
    "    writer.add_scalar('Dice score/Valid' , val_score, epoch)\n",
    "    scheduler.step(val_score)    \n",
    "\n",
    " \n",
    "    Path(checkpoint_path).mkdir(parents=True, exist_ok=True)\n",
    "    state_dict = model.state_dict()\n",
    "    # state_dict['mask_values'] = dataset.mask_values\n",
    "    torch.save(model, str(checkpoint_path + '/{}_checkpoint_epoch{}.pth'.format(model_name, epoch)))\n",
    "    print(f'Checkpoint {epoch} saved! in {checkpoint_path}')\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n",
      "torch.Size([1, 3, 1405, 1368])\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset_val, batch_size=1,\n",
    "                                        shuffle=False, pin_memory=True)\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "  \n",
    "    for batch in test_loader:\n",
    "        images, true_masks = batch[0], batch[1]\n",
    "        print(true_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seg_data.segDataset at 0x1e0dd8da890>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74,\n",
       " 65,\n",
       " 48,\n",
       " 97,\n",
       " 144,\n",
       " 1,\n",
       " 27,\n",
       " 106,\n",
       " 57,\n",
       " 84,\n",
       " 15,\n",
       " 49,\n",
       " 76,\n",
       " 61,\n",
       " 28,\n",
       " 125,\n",
       " 138,\n",
       " 130,\n",
       " 29,\n",
       " 54,\n",
       " 16,\n",
       " 71,\n",
       " 4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bettongia_penicillata_all_sutures_0095.tiff', 'Bettongia_penicillata_all_sutures_0115.tiff', 'Bettongia_penicillata_all_sutures_0135.tiff', 'Bettongia_penicillata_all_sutures_0155.tiff', 'Bettongia_penicillata_all_sutures_0175.tiff', 'Bettongia_penicillata_all_sutures_0195.tiff', 'Bettongia_penicillata_all_sutures_0215.tiff', 'Bettongia_penicillata_all_sutures_0235.tiff', 'Bettongia_penicillata_all_sutures_0255.tiff', 'Bettongia_penicillata_all_sutures_0275.tiff', 'Bettongia_penicillata_all_sutures_0295.tiff', 'Bettongia_penicillata_all_sutures_0315.tiff', 'Bettongia_penicillata_all_sutures_0335.tiff', 'Cebus_apella_all_sutures_0086.tiff', 'Cebus_apella_all_sutures_0106.tiff', 'Cebus_apella_all_sutures_0126.tiff', 'Cebus_apella_all_sutures_0146.tiff', 'Cebus_apella_all_sutures_0166.tiff', 'Cebus_apella_all_sutures_0186.tiff', 'Cebus_apella_all_sutures_0206.tiff', 'Cebus_apella_all_sutures_0226.tiff', 'Cebus_apella_all_sutures_0246.tiff', 'Cebus_apella_all_sutures_0266.tiff', 'Cebus_apella_all_sutures_0286.tiff', 'Cebus_apella_all_sutures_0306.tiff', 'Cebus_apella_all_sutures_0326.tiff', 'Cebus_apella_all_sutures_0346.tiff', 'Cebus_apella_all_sutures_0366.tiff', 'Cebus_apella_all_sutures_0386.tiff', 'Cebus_apella_all_sutures_0406.tiff', 'Cebus_apella_all_sutures_0426.tiff', 'Cebus_apella_all_sutures_0446.tiff', 'Cebus_apella_all_sutures_0466.tiff', 'Cebus_apella_all_sutures_0486.tiff', 'Cyclopes_didactylus_all_sutures_0525.tiff', 'Cyclopes_didactylus_all_sutures_0545.tiff', 'Cyclopes_didactylus_all_sutures_0565.tiff', 'Cyclopes_didactylus_all_sutures_0585.tiff', 'Cyclopes_didactylus_all_sutures_0605.tiff', 'Cyclopes_didactylus_all_sutures_0625.tiff', 'Cyclopes_didactylus_all_sutures_0645.tiff', 'Cyclopes_didactylus_all_sutures_0665.tiff', 'Cyclopes_didactylus_all_sutures_0685.tiff', 'Cyclopes_didactylus_all_sutures_0705.tiff', 'Cyclopes_didactylus_all_sutures_0725.tiff', 'Cyclopes_didactylus_all_sutures_0745.tiff', 'Cyclopes_didactylus_all_sutures_0765.tiff', 'Cyclopes_didactylus_all_sutures_0785.tiff', 'Cyclopes_didactylus_all_sutures_0805.tiff', 'Cyclopes_didactylus_all_sutures_0825.tiff', 'Cyclopes_didactylus_all_sutures_0845.tiff', 'Cyclopes_didactylus_all_sutures_0865.tiff', 'Cyclopes_didactylus_all_sutures_0885.tiff', 'Cyclopes_didactylus_all_sutures_0905.tiff', 'Dasyprocta_leporina_all_sutures_0209.tiff', 'Dasyprocta_leporina_all_sutures_0229.tiff', 'Dasyprocta_leporina_all_sutures_0249.tiff', 'Dasyprocta_leporina_all_sutures_0269.tiff', 'Dasyprocta_leporina_all_sutures_0289.tiff', 'Dasyprocta_leporina_all_sutures_0309.tiff', 'Dasyprocta_leporina_all_sutures_0329.tiff', 'Dasyprocta_leporina_all_sutures_0349.tiff', 'Dasyprocta_leporina_all_sutures_0369.tiff', 'Dasyprocta_leporina_all_sutures_0389.tiff', 'Dasyprocta_leporina_all_sutures_0409.tiff', 'Dasyprocta_leporina_all_sutures_0429.tiff', 'Dasyprocta_leporina_all_sutures_0449.tiff', 'Dasyprocta_leporina_all_sutures_0469.tiff', 'Dasyprocta_leporina_all_sutures_0489.tiff', 'Dasyprocta_leporina_all_sutures_0509.tiff', 'Dasyprocta_leporina_all_sutures_0529.tiff', 'Dasyprocta_leporina_all_sutures_0549.tiff', 'Dasyprocta_leporina_all_sutures_0569.tiff', 'Dasyprocta_leporina_all_sutures_0589.tiff', 'Dasyprocta_leporina_all_sutures_0609.tiff', 'Dasyprocta_leporina_all_sutures_0629.tiff', 'Dasyprocta_leporina_all_sutures_0649.tiff', 'Dasyprocta_leporina_all_sutures_0669.tiff', 'Dasyprocta_leporina_all_sutures_0689.tiff', 'Dasyprocta_leporina_all_sutures_0709.tiff', 'Macroscelides_proboscideus_all_sutures_0593.tiff', 'Macroscelides_proboscideus_all_sutures_0613.tiff', 'Macroscelides_proboscideus_all_sutures_0633.tiff', 'Macroscelides_proboscideus_all_sutures_0653.tiff', 'Macroscelides_proboscideus_all_sutures_0673.tiff', 'Macroscelides_proboscideus_all_sutures_0693.tiff', 'Macroscelides_proboscideus_all_sutures_0713.tiff', 'Macroscelides_proboscideus_all_sutures_0733.tiff', 'Macroscelides_proboscideus_all_sutures_0753.tiff', 'Macroscelides_proboscideus_all_sutures_0773.tiff', 'Macroscelides_proboscideus_all_sutures_0793.tiff', 'Macroscelides_proboscideus_all_sutures_0813.tiff', 'Macroscelides_proboscideus_all_sutures_0833.tiff', 'Macroscelides_proboscideus_all_sutures_0853.tiff', 'Macroscelides_proboscideus_all_sutures_0873.tiff', 'Macroscelides_proboscideus_all_sutures_0893.tiff', 'Monodelphis_domestica_all_sutures_00532.tiff', 'Monodelphis_domestica_all_sutures_00552.tiff', 'Monodelphis_domestica_all_sutures_00572.tiff', 'Monodelphis_domestica_all_sutures_00592.tiff', 'Monodelphis_domestica_all_sutures_00612.tiff', 'Monodelphis_domestica_all_sutures_00632.tiff', 'Monodelphis_domestica_all_sutures_00652.tiff', 'Mus_musculus_all_sutures_0267.tiff', 'Mus_musculus_all_sutures_0287.tiff', 'Mus_musculus_all_sutures_0307.tiff', 'Mus_musculus_all_sutures_0327.tiff', 'Mus_musculus_all_sutures_0347.tiff', 'Mus_musculus_all_sutures_0367.tiff', 'Mus_musculus_all_sutures_0387.tiff', 'Mus_musculus_all_sutures_0407.tiff', 'Mus_musculus_all_sutures_0427.tiff', 'Mus_musculus_all_sutures_0447.tiff', 'Sminthopsis_macroura_all_sutures_01260.tiff', 'Sminthopsis_macroura_all_sutures_01280.tiff', 'Sminthopsis_macroura_all_sutures_01300.tiff', 'Sminthopsis_macroura_all_sutures_01320.tiff', 'Sminthopsis_macroura_all_sutures_01340.tiff', 'Sminthopsis_macroura_all_sutures_01360.tiff', 'Sminthopsis_macroura_all_sutures_01380.tiff', 'Sminthopsis_macroura_all_sutures_01400.tiff', 'Sminthopsis_macroura_all_sutures_01420.tiff', 'Sminthopsis_macroura_all_sutures_01440.tiff', 'Sminthopsis_macroura_all_sutures_01460.tiff', 'Sminthopsis_macroura_all_sutures_01480.tiff', 'Sminthopsis_macroura_all_sutures_01500.tiff', 'Sminthopsis_macroura_all_sutures_01520.tiff', 'Sminthopsis_macroura_all_sutures_01540.tiff', 'Sminthopsis_macroura_all_sutures_01560.tiff', 'Sminthopsis_macroura_all_sutures_01580.tiff', 'Sminthopsis_macroura_all_sutures_01600.tiff', 'Sminthopsis_macroura_all_sutures_01620.tiff', 'Talpa_europaea_all_sutures_0532.tiff', 'Talpa_europaea_all_sutures_0552.tiff', 'Talpa_europaea_all_sutures_0572.tiff', 'Talpa_europaea_all_sutures_0592.tiff', 'Trichosurus_vulpecula_all_sutures_0550.tiff', 'Trichosurus_vulpecula_all_sutures_0570.tiff', 'Trichosurus_vulpecula_all_sutures_0590.tiff', 'Trichosurus_vulpecula_all_sutures_0610.tiff', 'Trichosurus_vulpecula_all_sutures_0630.tiff', 'Trichosurus_vulpecula_all_sutures_0650.tiff', 'Trichosurus_vulpecula_all_sutures_0670.tiff', 'Trichosurus_vulpecula_all_sutures_0690.tiff', 'Trichosurus_vulpecula_all_sutures_0710.tiff', 'Trichosurus_vulpecula_all_sutures_0730.tiff', 'Trichosurus_vulpecula_all_sutures_0750.tiff']\n",
      "['Bettongia_penicillata_all_sutures_0095.tiff', 'Bettongia_penicillata_all_sutures_0115.tiff', 'Bettongia_penicillata_all_sutures_0135.tiff', 'Bettongia_penicillata_all_sutures_0155.tiff', 'Bettongia_penicillata_all_sutures_0175.tiff', 'Bettongia_penicillata_all_sutures_0195.tiff', 'Bettongia_penicillata_all_sutures_0215.tiff', 'Bettongia_penicillata_all_sutures_0235.tiff', 'Bettongia_penicillata_all_sutures_0255.tiff', 'Bettongia_penicillata_all_sutures_0275.tiff', 'Bettongia_penicillata_all_sutures_0295.tiff', 'Bettongia_penicillata_all_sutures_0315.tiff', 'Bettongia_penicillata_all_sutures_0335.tiff', 'Cebus_apella_all_sutures_0086.tiff', 'Cebus_apella_all_sutures_0106.tiff', 'Cebus_apella_all_sutures_0126.tiff', 'Cebus_apella_all_sutures_0146.tiff', 'Cebus_apella_all_sutures_0166.tiff', 'Cebus_apella_all_sutures_0186.tiff', 'Cebus_apella_all_sutures_0206.tiff', 'Cebus_apella_all_sutures_0226.tiff', 'Cebus_apella_all_sutures_0246.tiff', 'Cebus_apella_all_sutures_0266.tiff', 'Cebus_apella_all_sutures_0286.tiff', 'Cebus_apella_all_sutures_0306.tiff', 'Cebus_apella_all_sutures_0326.tiff', 'Cebus_apella_all_sutures_0346.tiff', 'Cebus_apella_all_sutures_0366.tiff', 'Cebus_apella_all_sutures_0386.tiff', 'Cebus_apella_all_sutures_0406.tiff', 'Cebus_apella_all_sutures_0426.tiff', 'Cebus_apella_all_sutures_0446.tiff', 'Cebus_apella_all_sutures_0466.tiff', 'Cebus_apella_all_sutures_0486.tiff', 'Cyclopes_didactylus_all_sutures_0525.tiff', 'Cyclopes_didactylus_all_sutures_0545.tiff', 'Cyclopes_didactylus_all_sutures_0565.tiff', 'Cyclopes_didactylus_all_sutures_0585.tiff', 'Cyclopes_didactylus_all_sutures_0605.tiff', 'Cyclopes_didactylus_all_sutures_0625.tiff', 'Cyclopes_didactylus_all_sutures_0645.tiff', 'Cyclopes_didactylus_all_sutures_0665.tiff', 'Cyclopes_didactylus_all_sutures_0685.tiff', 'Cyclopes_didactylus_all_sutures_0705.tiff', 'Cyclopes_didactylus_all_sutures_0725.tiff', 'Cyclopes_didactylus_all_sutures_0745.tiff', 'Cyclopes_didactylus_all_sutures_0765.tiff', 'Cyclopes_didactylus_all_sutures_0785.tiff', 'Cyclopes_didactylus_all_sutures_0805.tiff', 'Cyclopes_didactylus_all_sutures_0825.tiff', 'Cyclopes_didactylus_all_sutures_0845.tiff', 'Cyclopes_didactylus_all_sutures_0865.tiff', 'Cyclopes_didactylus_all_sutures_0885.tiff', 'Cyclopes_didactylus_all_sutures_0905.tiff', 'Dasyprocta_leporina_all_sutures_0209.tiff', 'Dasyprocta_leporina_all_sutures_0229.tiff', 'Dasyprocta_leporina_all_sutures_0249.tiff', 'Dasyprocta_leporina_all_sutures_0269.tiff', 'Dasyprocta_leporina_all_sutures_0289.tiff', 'Dasyprocta_leporina_all_sutures_0309.tiff', 'Dasyprocta_leporina_all_sutures_0329.tiff', 'Dasyprocta_leporina_all_sutures_0349.tiff', 'Dasyprocta_leporina_all_sutures_0369.tiff', 'Dasyprocta_leporina_all_sutures_0389.tiff', 'Dasyprocta_leporina_all_sutures_0409.tiff', 'Dasyprocta_leporina_all_sutures_0429.tiff', 'Dasyprocta_leporina_all_sutures_0449.tiff', 'Dasyprocta_leporina_all_sutures_0469.tiff', 'Dasyprocta_leporina_all_sutures_0489.tiff', 'Dasyprocta_leporina_all_sutures_0509.tiff', 'Dasyprocta_leporina_all_sutures_0529.tiff', 'Dasyprocta_leporina_all_sutures_0549.tiff', 'Dasyprocta_leporina_all_sutures_0569.tiff', 'Dasyprocta_leporina_all_sutures_0589.tiff', 'Dasyprocta_leporina_all_sutures_0609.tiff', 'Dasyprocta_leporina_all_sutures_0629.tiff', 'Dasyprocta_leporina_all_sutures_0649.tiff', 'Dasyprocta_leporina_all_sutures_0669.tiff', 'Dasyprocta_leporina_all_sutures_0689.tiff', 'Dasyprocta_leporina_all_sutures_0709.tiff', 'Macroscelides_proboscideus_all_sutures_0593.tiff', 'Macroscelides_proboscideus_all_sutures_0613.tiff', 'Macroscelides_proboscideus_all_sutures_0633.tiff', 'Macroscelides_proboscideus_all_sutures_0653.tiff', 'Macroscelides_proboscideus_all_sutures_0673.tiff', 'Macroscelides_proboscideus_all_sutures_0693.tiff', 'Macroscelides_proboscideus_all_sutures_0713.tiff', 'Macroscelides_proboscideus_all_sutures_0733.tiff', 'Macroscelides_proboscideus_all_sutures_0753.tiff', 'Macroscelides_proboscideus_all_sutures_0773.tiff', 'Macroscelides_proboscideus_all_sutures_0793.tiff', 'Macroscelides_proboscideus_all_sutures_0813.tiff', 'Macroscelides_proboscideus_all_sutures_0833.tiff', 'Macroscelides_proboscideus_all_sutures_0853.tiff', 'Macroscelides_proboscideus_all_sutures_0873.tiff', 'Macroscelides_proboscideus_all_sutures_0893.tiff', 'Monodelphis_domestica_all_sutures_00532.tiff', 'Monodelphis_domestica_all_sutures_00552.tiff', 'Monodelphis_domestica_all_sutures_00572.tiff', 'Monodelphis_domestica_all_sutures_00592.tiff', 'Monodelphis_domestica_all_sutures_00612.tiff', 'Monodelphis_domestica_all_sutures_00632.tiff', 'Monodelphis_domestica_all_sutures_00652.tiff', 'Mus_musculus_all_sutures_0267.tiff', 'Mus_musculus_all_sutures_0287.tiff', 'Mus_musculus_all_sutures_0307.tiff', 'Mus_musculus_all_sutures_0327.tiff', 'Mus_musculus_all_sutures_0347.tiff', 'Mus_musculus_all_sutures_0367.tiff', 'Mus_musculus_all_sutures_0387.tiff', 'Mus_musculus_all_sutures_0407.tiff', 'Mus_musculus_all_sutures_0427.tiff', 'Mus_musculus_all_sutures_0447.tiff', 'Sminthopsis_macroura_all_sutures_01260.tiff', 'Sminthopsis_macroura_all_sutures_01280.tiff', 'Sminthopsis_macroura_all_sutures_01300.tiff', 'Sminthopsis_macroura_all_sutures_01320.tiff', 'Sminthopsis_macroura_all_sutures_01340.tiff', 'Sminthopsis_macroura_all_sutures_01360.tiff', 'Sminthopsis_macroura_all_sutures_01380.tiff', 'Sminthopsis_macroura_all_sutures_01400.tiff', 'Sminthopsis_macroura_all_sutures_01420.tiff', 'Sminthopsis_macroura_all_sutures_01440.tiff', 'Sminthopsis_macroura_all_sutures_01460.tiff', 'Sminthopsis_macroura_all_sutures_01480.tiff', 'Sminthopsis_macroura_all_sutures_01500.tiff', 'Sminthopsis_macroura_all_sutures_01520.tiff', 'Sminthopsis_macroura_all_sutures_01540.tiff', 'Sminthopsis_macroura_all_sutures_01560.tiff', 'Sminthopsis_macroura_all_sutures_01580.tiff', 'Sminthopsis_macroura_all_sutures_01600.tiff', 'Sminthopsis_macroura_all_sutures_01620.tiff', 'Talpa_europaea_all_sutures_0532.tiff', 'Talpa_europaea_all_sutures_0552.tiff', 'Talpa_europaea_all_sutures_0572.tiff', 'Talpa_europaea_all_sutures_0592.tiff', 'Trichosurus_vulpecula_all_sutures_0550.tiff', 'Trichosurus_vulpecula_all_sutures_0570.tiff', 'Trichosurus_vulpecula_all_sutures_0590.tiff', 'Trichosurus_vulpecula_all_sutures_0610.tiff', 'Trichosurus_vulpecula_all_sutures_0630.tiff', 'Trichosurus_vulpecula_all_sutures_0650.tiff', 'Trichosurus_vulpecula_all_sutures_0670.tiff', 'Trichosurus_vulpecula_all_sutures_0690.tiff', 'Trichosurus_vulpecula_all_sutures_0710.tiff', 'Trichosurus_vulpecula_all_sutures_0730.tiff', 'Trichosurus_vulpecula_all_sutures_0750.tiff']\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "dataset = seg_data.segDataset(img_path = img_path, \n",
    "    mask_path = mask_path, n_classes=n_classes,\n",
    "    scale=scale , start_class_i = start_class_i)\n",
    "\n",
    "print(dataset.masks)\n",
    "print(dataset.imgs)\n",
    "print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully.\n",
      "torch.Size([3, 1487, 1600])\n",
      "[0 1 2]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "\n",
    "image_path = \"C:/Users/sabbi/Downloads/project1/data_demo/img/Cebus_apella_all_sutures_0186.tiff\"\n",
    "image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "if image is None:\n",
    "    print(\"Failed to load image. Check the file path.\")\n",
    "else:\n",
    "    print(\"Image loaded successfully.\")\n",
    "    # Convert BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Convert to tensor\n",
    "    tensor_image = torch.from_numpy(image.transpose(2, 0, 1))  # CHW format\n",
    "    print(tensor_image.shape)\n",
    "\n",
    "mask = Image.open(\"C:/Users/sabbi/Downloads/project1/data_demo/mask/Cebus_apella_all_sutures_0186.tiff\").convert('L')\n",
    "w_mask, h_mask = mask.size\n",
    "mask = np.array(mask)\n",
    "print(np.unique(mask))\n",
    "\n",
    "mask_temp = np.zeros((h_mask, w_mask, 2))\n",
    "for i_class in range(2):\n",
    "    mask_temp[..., i_class] = np.where(mask == i_class, mask_temp[..., i_class], 1)\n",
    "\n",
    "print(mask_temp[..., 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(mask == 0,1 ,mask_temp[...,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "bde6227ca098a28506cae2de5e5d199190f968e09af08cbdae81bc10cc850e31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
